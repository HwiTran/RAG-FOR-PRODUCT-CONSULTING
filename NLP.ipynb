{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1-1fRt9lRr3wfbFms4GFFCJbHircqf7AT",
      "authorship_tag": "ABX9TyP4+Kmj+DQTzDpnZANdNzUY"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Get PDF file\n"
      ],
      "metadata": {
        "id": "V6rbCmkoSLnL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install library"
      ],
      "metadata": {
        "id": "fjnjgr13eLxh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "IONqKDV7R5HI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfe21b53-6b17-457b-e307-ddd07f151a10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.10/dist-packages (4.2.0)\n",
            "Requirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pypdf) (4.11.0)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.2.1-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: langchain-core in /usr/local/lib/python3.10/dist-packages (0.2.1)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.0.30)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (3.9.5)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.6-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: langchain<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.2.1)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.1.63)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (1.25.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (8.3.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core) (1.33)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core) (23.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core) (2.7.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.21.2-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core) (2.4)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.0->langchain-community) (0.2.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-community) (3.10.3)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core) (2.18.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.0.3)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, typing-inspect, dataclasses-json, langchain-community\n",
            "Successfully installed dataclasses-json-0.6.6 langchain-community-0.2.1 marshmallow-3.21.2 mypy-extensions-1.0.0 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "#Install the python library for PDF upload\n",
        "!pip install pypdf\n",
        "\n",
        "!pip install langchain-community langchain-core\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Import o\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "# importing required classes\n",
        "from pypdf import PdfReader"
      ],
      "metadata": {
        "id": "h9C1bm0mT_4o"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load PDF file"
      ],
      "metadata": {
        "id": "KbXqWJaPgDW7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_url = 'https://arxiv.org/pdf/1503.03832'\n",
        "loader = PyPDFLoader(pdf_url)\n",
        "pages = loader.load_and_split()"
      ],
      "metadata": {
        "id": "sNA7hAWMU3pH"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(pages)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EDlCVHLXgiA1",
        "outputId": "1c8fa720-3623-4f82-a436-34a283be9227"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(pages[15].page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lnvvNBXug0hc",
        "outputId": "5011432f-9797-4840-9132-f8c77d04159d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "learning for large margin nearest neighbor classiﬁcation. In\n",
            "NIPS . MIT Press, 2006. 2, 3\n",
            "[20] D. R. Wilson and T. R. Martinez. The general inefﬁciency\n",
            "of batch training for gradient descent learning. Neural Net-\n",
            "works , 16(10):1429–1451, 2003. 4\n",
            "[21] L. Wolf, T. Hassner, and I. Maoz. Face recognition in un-\n",
            "constrained videos with matched background similarity. In\n",
            "IEEE Conf. on CVPR , 2011. 5\n",
            "[22] M. D. Zeiler and R. Fergus. Visualizing and understanding\n",
            "convolutional networks. CoRR , abs/1311.2901, 2013. 2, 3,\n",
            "4, 6\n",
            "[23] Z. Zhu, P. Luo, X. Wang, and X. Tang. Recover canonical-\n",
            "view faces in the wild with deep neural networks. CoRR ,\n",
            "abs/1404.3543, 2014. 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# importing required modules\n",
        "from pypdf import PdfReader\n",
        "\n",
        "# creating a pdf reader object\n",
        "reader = PdfReader('/content/drive/MyDrive/Text summarize/facenet.pdf')\n",
        "\n",
        "# printing number of pages in pdf file\n",
        "print(len(reader.pages))\n",
        "\n",
        "# getting a specific page from the pdf file\n",
        "page = reader.pages[0]\n",
        "\n",
        "# extracting text from page\n",
        "text = page.extract_text()\n",
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9_5ZzS2h_f8",
        "outputId": "d871f40a-15b2-46ef-e906-44b924934b57"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n",
            "FaceNet: A Uniﬁed Embedding for Face Recognition and Clustering\n",
            "Florian Schroff\n",
            "fschroff@google.com\n",
            "Google Inc.Dmitry Kalenichenko\n",
            "dkalenichenko@google.com\n",
            "Google Inc.James Philbin\n",
            "jphilbin@google.com\n",
            "Google Inc.\n",
            "Abstract\n",
            "Despite signiﬁcant recent advances in the ﬁeld of face\n",
            "recognition [10, 14, 15, 17], implementing face veriﬁcation\n",
            "and recognition efﬁciently at scale presents serious chal-\n",
            "lenges to current approaches. In this paper we present a\n",
            "system, called FaceNet, that directly learns a mapping from\n",
            "face images to a compact Euclidean space where distances\n",
            "directly correspond to a measure of face similarity. Once\n",
            "this space has been produced, tasks such as face recogni-\n",
            "tion, veriﬁcation and clustering can be easily implemented\n",
            "using standard techniques with FaceNet embeddings as fea-\n",
            "ture vectors.\n",
            "Our method uses a deep convolutional network trained\n",
            "to directly optimize the embedding itself, rather than an in-\n",
            "termediate bottleneck layer as in previous deep learning\n",
            "approaches. To train, we use triplets of roughly aligned\n",
            "matching / non-matching face patches generated using a\n",
            "novel online triplet mining method. The beneﬁt of our\n",
            "approach is much greater representational efﬁciency: we\n",
            "achieve state-of-the-art face recognition performance using\n",
            "only 128-bytes per face.\n",
            "On the widely used Labeled Faces in the Wild (LFW)\n",
            "dataset, our system achieves a new record accuracy of\n",
            "99.63% . On YouTube Faces DB it achieves 95.12% . Our\n",
            "system cuts the error rate in comparison to the best pub-\n",
            "lished result [15] by 30% on both datasets.\n",
            "We also introduce the concept of harmonic embeddings,\n",
            "and a harmonic triplet loss, which describe different ver-\n",
            "sions of face embeddings (produced by different networks)\n",
            "that are compatible to each other and allow for direct com-\n",
            "parison between each other.\n",
            "1. Introduction\n",
            "In this paper we present a uniﬁed system for face veri-\n",
            "ﬁcation (is this the same person), recognition (who is this\n",
            "person) and clustering (ﬁnd common people among these\n",
            "faces). Our method is based on learning a Euclidean em-\n",
            "bedding per image using a deep convolutional network. The\n",
            "network is trained such that the squared L2 distances in\n",
            "the embedding space directly correspond to face similarity:\n",
            "1.04\n",
            "1.22 1.33\n",
            "0.78\n",
            "1.33 1.26\n",
            "0.99\n",
            "Figure 1. Illumination and Pose invariance. Pose and illumina-\n",
            "tion have been a long standing problem in face recognition. This\n",
            "ﬁgure shows the output distances of FaceNet between pairs of\n",
            "faces of the same and a different person in different pose and il-\n",
            "lumination combinations. A distance of 0.0means the faces are\n",
            "identical, 4.0corresponds to the opposite spectrum, two different\n",
            "identities. You can see that a threshold of 1.1 would classify every\n",
            "pair correctly.\n",
            "faces of the same person have small distances and faces of\n",
            "distinct people have large distances.\n",
            "Once this embedding has been produced, then the afore-\n",
            "mentioned tasks become straight-forward: face veriﬁca-\n",
            "tion simply involves thresholding the distance between the\n",
            "two embeddings; recognition becomes a k-NN classiﬁca-\n",
            "tion problem; and clustering can be achieved using off-the-\n",
            "shelf techniques such as k-means or agglomerative cluster-\n",
            "ing.\n",
            "Previous face recognition approaches based on deep net-\n",
            "works use a classiﬁcation layer [15, 17] trained over a set of\n",
            "known face identities and then take an intermediate bottle-\n",
            "1arXiv:1503.03832v3  [cs.CV]  17 Jun 2015\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "page.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "xp8FnBzIj06o",
        "outputId": "6843fd9c-adc4-43df-b3ae-9d18bb990fc0"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'PageObject' object has no attribute 'info'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-37b8d22cb61f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'PageObject' object has no attribute 'info'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iPXdM5UakZGA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}